# DLPDF - ウェブサイトをPDFに変換するツール

`download`（ダウンロードとPDF化）は、指定されたウェブサイトのページを効率的に収集し、それらをPDFファイルに変換するためのシェルスクリプトです。サイトマップや自動クロールを活用して、効率的にウェブコンテンツをPDF形式で保存します。

## 機能

- サイトマップからURLを自動収集
- robots.txtからのサイトマップ検出
- ウェブクローリングによるURL収集
- Google Chromeのヘッドレスモードを使用したPDF変換
- 複数のURLの一括処理
- 処理するURLの数とクロール深さの制限
- 対話的な確認オプション

## 必要条件

- bash シェル
- curl, wget, grep, sed, awk
- Google Chrome（PDF変換に使用）

## インストール方法

1. このリポジトリをクローンまたはダウンロードします
2. スクリプトの実行権限を付与します：

```bash
chmod +x download_and_pdf.sh
```

## 使用方法

```bash
./download_and_pdf.sh [オプション] <base_url>
```

### オプション

| オプション | 説明 |
|------------|------|
| `-h, --help` | ヘルプメッセージを表示 |
| `-o, --output DIR` | PDFの出力先ディレクトリを指定（デフォルト: Download） |
| `-a, --all` | 確認なしですべてのURLを処理 |
| `-m, --max NUM` | 処理するURLの最大数を指定 |
| `-d, --depth NUM` | クロールする深さを指定（デフォルト: 1） |
| `--debug` | 一時ファイルを保持（デバッグ用） |
| `--wait NUM` | ページ間の待機時間（秒） |

### 使用例

基本的な使用方法:
```bash
./download_and_pdf.sh https://nextjs.org/docs/app
```

すべてのURLを自動処理し、出力先を指定:
```bash
./download_and_pdf.sh --all --output nextjs_docs https://nextjs.org/docs/app
```

最大50ページまでで深さ2までクロール:
```bash
./download_and_pdf.sh --max 50 --depth 2 https://example.com
```

## 動作の仕組み

1. スクリプトは指定されたベースURLからスタート
2. 以下の方法を順番に試してURLを収集:
   - サイトマップ（sitemap.xml）
   - robots.txtからサイトマップ情報
   - wgetによるウェブクローリング
3. 収集したURLを処理し、Google Chromeのヘッドレスモードを使用してPDFに変換
4. 結果を指定されたディレクトリに保存

## 制限事項

- JavaScriptによる動的コンテンツは完全にレンダリングされない場合があります
- ログインが必要なページには対応していません
- 大量のURLを処理する場合は、サーバーに過度な負荷をかけないよう--waitオプションで待機時間を調整してください

## トラブルシューティング

### PDF変換に失敗する場合

- Google Chromeが正しくインストールされているか確認してください
- --debug オプションを使用してデバッグ情報を確認してください
- ページの読み込みが遅い場合は --wait オプションで待機時間を増やしてみてください

### URLが収集できない場合

- ウェブサイトがクローラーをブロックしていないか確認してください
- --depth オプションを使用してクロール深度を増やしてみてください
